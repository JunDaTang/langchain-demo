{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c9caf9f45ff0ece",
   "metadata": {},
   "source": [
    "# 1、获取大模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce788165255a6aee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T13:49:13.042306Z",
     "start_time": "2025-08-21T13:49:05.622065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='“大模型”通常指的是一种具有大量参数和复杂结构的深度学习模型，特别是在自然语言处理、计算机视觉等领域。大模型的一个显著特点是它们能够通过大规模的数据进行预训练，从而学习到丰富的特征和知识。\\n\\n以下是大模型的一些重要特点和应用：\\n\\n1. **参数规模**：大模型通常包含数亿到数千亿个参数，这使得它们能够捕捉到更复杂的模式和关系。\\n\\n2. **预训练与微调**：大模型通常采用预训练和微调的策略。先在大规模数据集上进行无监督或自监督学习，然后在特定任务上进行微调，以适应特定应用场景。\\n\\n3. **应用广泛**：大模型在许多领域都取得了显著的成果，包括但不限于文本生成（例如GPT系列）、图像生成（如DALL-E）、翻译（如Transformer模型）等。\\n\\n4. **计算资源要求高**：由于参数的庞大和复杂度，大模型的训练和推理需要大量的计算资源，通常依赖于高性能的GPU集群或者TPU。\\n\\n5. **迁移学习**：大模型能够通过迁移学习的方式，将在某一任务上学到的知识迁移到其他任务上，从而提升模型的表现。\\n\\n大模型的出现推动了人工智能的发展，使得许多原本难以解决的问题变得可行。但同时，它们也带来了模型训练和使用中的伦理、资源消耗等方面的挑战。' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 342, 'prompt_tokens': 12, 'total_tokens': 354, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_f97eff32c5', 'id': 'chatcmpl-CraRT040V6QBufMEBTIfBjtOOpFW3', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b62b3-b43f-7b13-91e9-7009b9de4a10-0' usage_metadata={'input_tokens': 12, 'output_tokens': 342, 'total_tokens': 354, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "#导入 dotenv 库的 load_dotenv 函数，用于加载环境变量文件（.env）中的配置\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv()  #加载当前目录下的 .env 文件\n",
    "\n",
    "# 安全地设置环境变量，处理可能的None值\n",
    "api_key = os.getenv(\"OPENAI_API_KEY1\")\n",
    "if api_key:\n",
    "    os.environ['OPENAI_API_KEY'] = api_key\n",
    "    \n",
    "base_url = os.getenv(\"OPENAI_BASE_URL\")\n",
    "if base_url:\n",
    "    os.environ['OPENAI_BASE_URL'] = base_url\n",
    "\n",
    "# 创建大模型实例\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")  # 默认使用 gpt-3.5-turbo\n",
    "\n",
    "# 直接提供问题，并调用llm\n",
    "response = llm.invoke(\"什么是大模型？\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd908d3010884a30",
   "metadata": {},
   "source": [
    "# 2、使用提示词模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3540706aaa244853",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T13:50:29.883037Z",
     "start_time": "2025-08-21T13:50:21.403902Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='LangChain 是一个用于构建与语言模型交互的应用程序和工具的框架。它的目标是简化和加速开发人员在自然语言处理 (NLP) 领域的工作，特别是与大型语言模型 (LLMs) 的集成。LangChain 的设计理念是提供一套模块化的组件，使开发者能够轻松构建、扩展和优化与语言模型相关的应用。\\n\\n### LangChain 的主要组成部分包括：\\n\\n1. **模型封装**：\\n   LangChain 提供了简单的接口来与不同的语言模型（如 OpenAI GPT、Google BERT 等）进行交互，让开发者可以轻松切换和配置不同的模型。\\n\\n2. **数据连接**：\\n   LangChain 支持多种数据源的连接，如数据库、API 和本地文件，可以将这些数据源与语言模型的输入和输出相结合，增强应用的智能性。\\n\\n3. **链式结构**：\\n   LangChain 使用“链”的概念，允许开发者将多个处理步骤组合在一起。例如，可以将文本预处理、模型推理和后处理等步骤串联成一个工作流，提高代码的可读性和可维护性。\\n\\n4. **自定义和扩展**：\\n   开发者可以根据需求自定义链的行为和各个组件，使 LangChain 适应特定应用场景的需求。 例如，可以创建自定义的解析器、格式化器或模型调用器。\\n\\n5. **内置工具**：\\n   LangChain 提供了一些内置工具和模块，以简化常见的任务，如文本摘要、问答、对话系统等。这些功能可以直接使用，节省开发时间。\\n\\n6. **社区和支持**：\\n   LangChain 拥有活跃的社区和丰富的文档，开发者可以在社区中寻求帮助或分享他们的经验和项目。\\n\\n### 应用场景\\nLangChain 可以应用于多种场景，包括但不限于：\\n- 聊天机器人\\n- 内容生成\\n- 数据分析\\n- 问答系统\\n- 资源推荐\\n\\n### 总结\\nLangChain 是一个强大且灵活的框架，旨在为开发人员提供构建与大型语言模型交互的应用所需的工具和环境，能够加快开发进程并提高应用的智能化程度。' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 508, 'prompt_tokens': 29, 'total_tokens': 537, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_f97eff32c5', 'id': 'chatcmpl-CrRmBZbyQ5viwxNMFm6VEAD8Tg6l0', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b60b7-6b79-7541-b596-3e22177b29ff-0' usage_metadata={'input_tokens': 29, 'output_tokens': 508, 'total_tokens': 537, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 需要注意的一点是，这里需要指明具体的role，在这里是system和用户\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是世界级的技术文档编写者\"),\n",
    "    (\"user\", \"{input}\")  # {input}为变量\n",
    "])\n",
    "\n",
    "# 我们可以把prompt和具体llm的调用和在一起。\n",
    "chain = prompt | llm\n",
    "message = chain.invoke({\"input\": \"大模型中的LangChain是什么?\"})\n",
    "print(message)\n",
    "\n",
    "# print(type(message))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7636c01962fa0c2e",
   "metadata": {},
   "source": [
    "# 3、 使用输出解析器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23406024ea864619",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T13:51:18.550994Z",
     "start_time": "2025-08-21T13:51:16.084164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'LangChain是什么?',\n",
       " 'answer': 'LangChain是一个用于构建与大型语言模型（LLM）互动的应用程序的框架。它提供了一系列工具和组件，以帮助开发者更轻松地创建复杂的应用，如聊天机器人、文本生成工具以及其他基于语言模型的功能。LangChain支持不同的数据源和输出选项，允许用户自定义语言模型的行为，并集成外部API和服务。'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# 初始化模型\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 创建提示模板\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是世界级的技术文档编写者。\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "# 使用输出解析器\n",
    "output_parser = JsonOutputParser()\n",
    "\n",
    "# 将其添加到上一个链中\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "# 调用它并提出同样的问题。答案是一个字符串，而不是ChatMessage\n",
    "chain.invoke({\"input\": \"LangChain是什么? 用JSON格式回复，问题用question，回答用answer\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152461370a49413f",
   "metadata": {},
   "source": [
    "# 4、使用向量存储"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c182765067f9f4eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T13:53:08.453078Z",
     "start_time": "2025-08-21T13:52:40.823449Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'https://www.gov.cn/yaowen/liebiao/202512/content_7052417.htm'}, page_content='\\n李强主持召开国务院“十五五”规划《纲要草案》编制工作领导小组会议强调深入学习贯彻习近平总书记重要讲话精神进一步做好“十五五”规划纲要编制工作丁薛祥出席新华社北京12月22日电 12月22日，中共中央政治局常委、国务院总理李强主持召开国务院“十五五”规划《纲要草案》编制工作领导小组会议，深入研究《纲要草案》编制工作。中共中央政治局常委、国务院副总理丁薛祥出席。12月22日，中共中央政治局常委、国务院总理李强在北京主持召开国务院“十五五”规划《纲要草案》编制工作领导小组会议，深入研究《纲要草案》编制工作。中共中央政治局常委、国务院副总理丁薛祥出席。新华社记者 黄敬文 摄会上，国家发展改革委就《纲要草案》编制进展情况作了汇报，与会同志进行了讨论。李强说，编制“十五五”规划纲要是当前一项重要任务，习近平总书记在中央经济工作会议上对做好规划纲要编制工作提出明确要求，我们要深入学习领会、认真贯彻落实，进一步做好《纲要草案》编制工作。李强指出，目前《纲要草案》的编制已经有了较好基础，下一步要集中力量、精益求精做好修改完善工作。要着眼于更好发挥规划引领作用，紧紧围绕推动高质量发展这个主题来设定指标、安排政策、谋划项目，推动经济实现质的有效提升和量的合理增长。致力于发展新质生产力，在推动科技创新、加快培育新动能、促进经济结构优化升级上取得突破性进展。要进一步明确任务举措，围绕“十五五”规划建议明确的战略任务做好细化实化工作，使规划内容更加贴近发展需要。谋划一批能够带动全局的重大工程、重大项目、重大载体，既为未来发展积聚新动能、培育竞争力，又为当前扩大内需、稳定经济运行提供支撑。要深入贯彻改革创新的要求，准确把握当前发展的阶段性特征，克服路径依赖，善于运用改革创新的办法破解难题。坚持政策支持和改革创新并举，聚焦打通体制机制上的堵点卡点，深入谋划新政策新举措，形成组合放大效应。要充分体现民生温度，回应社会关切，推出一批惠民生暖民心的重大政策和项目，切实解决群众急难愁盼问题。找准改善民生和扩大内需的结合点，在增进民生福祉中培育新的经济增长点。李强强调，《纲要草案》编制要充分发扬民主，广泛凝聚共识，认真听取并吸纳各方面意见建议，汇集各方智慧，形成发展合力。何立峰、张国清、刘国中、王小洪、吴政隆参加会议。\\n\\n\\n')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# 导入和使用 WebBaseLoader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from bs4.filter import SoupStrainer\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "        web_path=\"https://www.gov.cn/yaowen/liebiao/202512/content_7052417.htm\",\n",
    "        bs_kwargs=dict(parse_only=SoupStrainer(id=\"UCAP-CONTENT\"))\n",
    "    )\n",
    "docs = loader.load()\n",
    "print(docs)\n",
    "\n",
    "# 对于嵌入模型，这里通过 API调用\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "\n",
    "# 使用分割器分割文档\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "documents = text_splitter.split_documents(docs)\n",
    "print(len(documents))\n",
    "# 向量存储  embeddings 会将 documents 中的每个文本片段转换为向量，并将这些向量存储在 FAISS 向量数据库中\n",
    "if documents:\n",
    "    vector = FAISS.from_documents(documents, embeddings)\n",
    "else:\n",
    "    print(\"警告：没有加载到文档，跳过向量存储创建\")\n",
    "    vector = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795b38c85dfb39fe",
   "metadata": {},
   "source": [
    "# 5、RAG(检索增强生成)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcfa2c4bd0704d50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T13:54:32.319977Z",
     "start_time": "2025-08-21T13:54:25.549076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "参加会议的有中共中央政治局常委、国务院总理李强，中共中央政治局常委、国务院副总理丁薛祥，以及何立峰、张国清、刘国中、王小洪、吴政隆。\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "if vector is not None:\n",
    "    retriever = vector.as_retriever()\n",
    "    retriever.search_kwargs = {\"k\": 3}\n",
    "    docs = retriever.invoke(\"谁参加会议？\")\n",
    "\n",
    "    # for i,doc in enumerate(docs):\n",
    "    #     print(f\"⭐第{i+1}条规定：\")\n",
    "    #     print(doc)\n",
    "\n",
    "    # 6.定义提示词模版\n",
    "    prompt_template = \"\"\"\n",
    "    你是一个问答机器人。\n",
    "    你的任务是根据下述给定的已知信息回答用户问题。\n",
    "    确保你的回复完全依据下述已知信息。不要编造答案。\n",
    "    如果下述已知信息不足以回答用户的问题，请直接回复\"我无法回答您的问题\"。\n",
    "\n",
    "    已知信息:\n",
    "    {info}\n",
    "\n",
    "    用户问：\n",
    "    {question}\n",
    "\n",
    "    请用中文回答用户问题。\n",
    "    \"\"\"\n",
    "    # 7.得到提示词模版对象\n",
    "    template = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "    # 8.得到提示词对象\n",
    "    prompt = template.format(info=docs, question='谁参加会议？')\n",
    "\n",
    "    ## 9. 调用LLM\n",
    "    response = llm.invoke(prompt)\n",
    "    print(response.content)\n",
    "else:\n",
    "    print(\"无法执行RAG：向量存储未创建\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9feeb62844c3439",
   "metadata": {},
   "source": [
    "# 6、使用Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26eb95f11df6bc53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T13:56:14.407134Z",
     "start_time": "2025-08-21T13:56:03.168429Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Tool' from 'langchain.tools' (e:\\BaiduSyncdisk\\github\\langchain-demo\\.venv\\Lib\\site-packages\\langchain\\tools\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tool\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m hub\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01magents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_openai_functions_agent\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'Tool' from 'langchain.tools' (e:\\BaiduSyncdisk\\github\\langchain-demo\\.venv\\Lib\\site-packages\\langchain\\tools\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain.tools import Tool\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# 检索器工具 - 使用Tool类创建\n",
    "retriever_tool = Tool(\n",
    "    name=\"CivilCodeRetriever\",\n",
    "    func=retriever.invoke,\n",
    "    description=\"搜索有关中华人民共和国民法典的信息。关于中华人民共和国民法典的任何问题，您必须使用此工具!\"\n",
    ")\n",
    "\n",
    "tools = [retriever_tool]\n",
    "\n",
    "# https://smith.langchain.com/hub\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# 运行代理\n",
    "agent_executor.invoke({\"input\": \"谁参加会议？\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
